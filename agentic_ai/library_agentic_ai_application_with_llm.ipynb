{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2b098fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eb18543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "my_api_key =os.getenv(\"OPENAI_API_KEY\")\n",
    "#print (f'key is {my_api_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0ebd684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibraryState(TypedDict):\n",
    "        question: str\n",
    "        faq_answer: str\n",
    "        checkout_info: str\n",
    "        final_answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "11ad21d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=my_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e424464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifierAgent(state: LibraryState):\n",
    "    print (\"ClassifierAgent ran\")\n",
    "    print(f\"state:{state}\")\n",
    "\n",
    "    # Build the LLM Message\n",
    "    message_to_llm = [\n",
    "        {\"role\":\"system\", \"content\": ''' You are a classifier agent in a library system. Decide if the user is asking \n",
    "         about book availability/checkout or about library FAQs. Reply with JSON containing keys: faq_answer and checkout_info.'''},\n",
    "        {\"role\":\"user\", \"content\": f\"Question: {state['question']}\"}\n",
    "    ]\n",
    "\n",
    "    # Call the OpenAI model\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=message_to_llm,\n",
    "        temperature=1,   # keep it deterministic for classification\n",
    "        #max_tokens=150,\n",
    "    )\n",
    "\n",
    "    print (response)\n",
    "    # Extract the content from the response\n",
    "    answer = response.choices[0].message.content\n",
    "    # Ideally, parse as JSON — here assuming model returns a dict-like string\n",
    "    try:\n",
    "        import json\n",
    "        parsed = json.loads(answer)\n",
    "        return {\n",
    "            \"faq_answer\": parsed.get(\"fag_answer\",\"\"),\n",
    "            \"checkout_info\": parsed.get(\"checkout_info\",\"\")\n",
    "        }\n",
    "    except Exception:\n",
    "        # fallback if LLM gives plain text\n",
    "        return {\"faq_answer\": answer, \"checkout_info\": \"\"}\n",
    "    \n",
    "    #@traceble \n",
    "\n",
    "\n",
    "\n",
    "def FAQAgent(state: LibraryState):\n",
    "    print(\"FAQAgent ran\")\n",
    "    print(f\"FAQAgent state\", state)\n",
    "    \n",
    "    # return {}\n",
    "    return {\"faq_answer\": \"The library opens at 9:00 AM\"}\n",
    "\n",
    "def CheckoutAgent(state: LibraryState):\n",
    "    print(\"CheckoutAgent ran\")\n",
    "    \n",
    "    # return {}\n",
    "    return {\"checkout_info\": \"The Hobbit is available for checkout.\"}\n",
    "\n",
    "def ResponseAgent(state: LibraryState):\n",
    "    print(\"ResponseAgent ran\")\n",
    "    \n",
    "    #return {\"final_answer\": \"RESPONSE AGENT FINAL ANSWER\"}\n",
    "    return {\"final_answer\": f\"FAQ: {state['faq_answer']} | Checkout: {state['checkout_info']}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8e461401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifierAgent ran\n",
      "state:{'question': 'When does library open?'}\n",
      "ChatCompletion(id='chatcmpl-CDEsljtItSJg8ewdb9aGbG21OHs4h', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"faq_answer\": \"Do you mean a specific branch? I don\\'t know which library you mean. Please tell me the branch or location so I can give exact hours. (Typical public-library hours are often Mon–Fri 9:00 AM–6:00 PM, Sat 9:00 AM–1:00 PM, Sun closed; check the library\\'s website or call the branch to confirm.)\",\\n  \"checkout_info\": null\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757271507, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=486, prompt_tokens=57, total_tokens=543, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=384, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "CheckoutAgent ran\n",
      "FAQAgent ran\n",
      "FAQAgent state {'question': 'When does library open?', 'faq_answer': '', 'checkout_info': None}\n",
      "ResponseAgent ran\n",
      "\n",
      "--Final Answer--\n",
      "FAQ: The library opens at 9:00 AM | Checkout: The Hobbit is available for checkout.\n"
     ]
    }
   ],
   "source": [
    "# --- Build the Graph ---\n",
    "builder = StateGraph(LibraryState)\n",
    "builder.add_node(\"ClassifierAgent\", ClassifierAgent)\n",
    "builder.add_node(\"FAQAgent\", FAQAgent)\n",
    "builder.add_node(\"CheckoutAgent\", CheckoutAgent)\n",
    "builder.add_node(\"ResponseAgent\", ResponseAgent)\n",
    "\n",
    "builder.add_edge(START, \"ClassifierAgent\")\n",
    "builder.add_edge(\"ClassifierAgent\", \"FAQAgent\")\n",
    "builder.add_edge(\"ClassifierAgent\", \"CheckoutAgent\")\n",
    "builder.add_edge(\"FAQAgent\", \"ResponseAgent\")\n",
    "builder.add_edge(\"CheckoutAgent\", \"ResponseAgent\")\n",
    "builder.add_edge(\"ResponseAgent\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "result = graph.invoke({\"question\": \"When does library open?\"})\n",
    "print(\"\\n--Final Answer--\")\n",
    "print(result[\"final_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9b82d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize ---\n",
    "#pip install grandalf\n",
    "\n",
    "#print(graph.get_graph().draw_ascii())\n",
    "# graph.get_graph().draw_png(\"images/agentic_ai_library.png\")\n",
    "# print(\"Graph saved as agentic_ai_library.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
